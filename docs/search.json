[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "calculating-lst-and-nvdi.html",
    "href": "calculating-lst-and-nvdi.html",
    "title": "Calculate LST and NVDI",
    "section": "",
    "text": "# https://downloads.hindawi.com/journals/js/2016/1480307.pdf\n# http://www.gisandbeers.com/GeoBazar/Libros/Teledeteccion/Manual-Landsat-9-Handbook.pdf\nlibrary(raster)\n\nLoading required package: sp\n\n# Load data\nd <- \"../../../OneDrive/Data/landstat/LC09_L2SP_202024_20220826_20220830_02_T1/\"\n\nred = raster(file.path(d, \"LC09_L2SP_202024_20220826_20220830_02_T1_SR_B4.TIF\"))\nnear.infrared = raster(file.path(d, \"LC09_L2SP_202024_20220826_20220830_02_T1_SR_B5.TIF\"))\nband_10 = raster(file.path(d, \"LC09_L2SP_202024_20220826_20220830_02_T1_ST_B10.TIF\"))\nmeta <- readLines(file.path(d, \"LC09_L2SP_202024_20220826_20220830_02_T1_MTL.txt\"))\n\nM_L <- meta[stringr::str_detect(meta, \"RADIANCE_MULT_BAND_10\")] |>\n  stringr::str_split(\" = \") |>\n  unlist() |>\n  dplyr::nth(2) |>\n  as.numeric()\n\nA_L <- meta[stringr::str_detect(meta, \"RADIANCE_ADD_BAND_10\")] |>\n  stringr::str_split(\" = \") |>\n  unlist() |>\n  dplyr::nth(2) |>\n  as.numeric()\n\ntoa <- M_L * band_10 + A_L\n\nK_1 <- meta[stringr::str_detect(meta, \"K1_CONSTANT_BAND_10\")] |>\n  stringr::str_split(\" = \") |>\n  unlist() |>\n  dplyr::nth(2) |>\n  as.numeric()\n\nK_2 <- meta[stringr::str_detect(meta, \"K2_CONSTANT_BAND_10\")] |>\n  stringr::str_split(\" = \") |>\n  unlist() |>\n  dplyr::nth(2) |>\n  as.numeric()\n\nBT <- (K_2 / (log(K_1/toa)+1))- 273.15 # kevin to celcius\n\nnvdi_s <- 0.2\nnvdi_v <- 0.5\nnvdi <- (near.infrared - red)/(near.infrared + red)\n\np_v <- nvdi\np_v@data@values <- ((p_v@data@values - nvdi_s)/(nvdi_v-nvdi_s))^2\n\n\n# If nvdi less than 0 then water and emissivity (e_w) is 0.991\n# If nvdi < nvdi_s then emissivity (e_s) is 0.0996\n# If nvdi > nvdi_v then emissivity (e_v) is 0.973\n# if nvdi is between 0.2 and 0.5 then  e_v*P_V + e_s(1-P_V)+C_l\n\ne_w <- 0.991\ne_s <- 0.996\ne_v <- 0.973\nC_l <- 0.005 # correction\n\ne <- p_v\ne@data@values <- ifelse(\n  e@data@values <= 0, e_w, ifelse(\n    e@data@values >0 & e@data@values <= nvdi_s, e_s, ifelse(\n      e@data@values > nvdi_s & e@data@values <= nvdi_v, e_v * e@data@values + e_s * (1-e@data@values) + C_l, e_v\n      )\n  )\n)\n\nlambda <- 10.895 # average limiting wavelength\nrho <- 1.438 * 10e-2 # see paper\n\nLST <- (BT / (1 + (0.0010895 * BT / 1.4388) * log(e)))\nplot(LST)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "seven",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "lst-by-building.html",
    "href": "lst-by-building.html",
    "title": "What is Land Surface Temperature Building for a given site?",
    "section": "",
    "text": "library(sf)\n\nLinking to GEOS 3.9.1, GDAL 3.4.3, PROJ 7.2.1; sf_use_s2() is TRUE\n\nlibrary(leaflet)\nlibrary(raster)\n\nLoading required package: sp\n\nlibrary(ggplot2)\nsource(\"R/postgis.R\")"
  },
  {
    "objectID": "lst-by-building.html#aggregate-raster-over-polygon",
    "href": "lst-by-building.html#aggregate-raster-over-polygon",
    "title": "What is Land Surface Temperature Building for a given site?",
    "section": "Aggregate Raster over Polygon",
    "text": "Aggregate Raster over Polygon\n\n# https://deepnote.com/@sookyan-siew/R-Aggregate-raster-to-polygon-data-10a3150c-e88d-4776-bae1-4b6dcb9e3916 \n# https://stackoverflow.com/questions/67717866/r-aggregating-raster-to-shapefile-polygons\n# Same projection\nlst3 <- projectRaster(lst2, crs = crs(buildings))\nplot(st_geometry(buildings))\nplot(lst3, add = TRUE)\nplot(st_geometry(buildings), add = TRUE)\n\n\n\navg_lst <- raster::extract(lst3, buildings, mean, na.rm = TRUE)\n\nbuildings$lst <- as.numeric(avg_lst)\n\n\npal <- colorNumeric(c(\"#0C2C84\", \"#41B6C4\", \"#FFFFCC\"), buildings$lst,\n  na.color = \"transparent\")\n\nleaflet(options = leafletOptions(minZoom = 14, maxZoom = 17)) |>\n   addTiles(group = \"OSM (default)\") |>\n  addProviderTiles(providers$Stamen.Toner, group = \"Toner\") |>\n  addProviderTiles(providers$Stamen.TonerLite, group = \"Toner Lite\") |>\n  fitBounds(lng1, lat1, lng2, lat2) |>\n  setMaxBounds(lng1, lat1, lng2, lat2) |>\n  addPolygons(data = buildings, fillColor =  ~pal(lst), \n              color = \"black\", weight = 0, fillOpacity = 0.8,\n              label = ~round(lst,1),\n              popup = ~paste(\"<b>ID:</b>\", FEATCODE, \"<br>\", \"<b>LST:</b>\", round(lst,1))) |>\n   addLegend(pal = pal, values = buildings$lst,\n    title = \"Surface temp\")   |>\n  addLayersControl(\n    baseGroups = c(\"OSM (default)\", \"Toner\", \"Toner Lite\"),\n    options = layersControlOptions(collapsed = FALSE)\n  )"
  },
  {
    "objectID": "mask-clouds.html",
    "href": "mask-clouds.html",
    "title": "Remove Clouds",
    "section": "",
    "text": "mask_values <- qa_lu |>\n  dplyr::filter(Cloud == \"Yes\") |>\n  dplyr::pull(`Pixel Value`)\n\nqa[qa %in% mask_values] <- NA\nmr <- mask(red, qa)\n\n\nplot(red)\n\n\n\nplot(mr)"
  },
  {
    "objectID": "overlapping-sites.html",
    "href": "overlapping-sites.html",
    "title": "Overlaping Sites",
    "section": "",
    "text": "db <- connect_postgres()\nDBI::dbListTables(db)\n\n[1] \"geography_columns\"     \"geometry_columns\"      \"spatial_ref_sys\"      \n[4] \"mil_boundaries_osm\"    \"mil_build_os\"          \"mil_build_features\"   \n[7] \"mil_bound_clust_osm\"   \"sites_202024_20220826\"\n\nsites <- st_read(db, \"mil_boundaries_osm\") |>\n  dplyr::select(osm_id, name, aeroway, description, landuse, military)\n\nDBI::dbDisconnect(db)\n\n\ng <-st_intersects(sites) |>\n  graph_from_adj_list()\ncomp <- components(g)\nsites$cluster <- comp$membership\n\nsites_clustered <- sites |> \n  dplyr::group_by(cluster) |>\n  dplyr::summarise(geometry = st_union(geometry)) \n\n\n# Add label to site based on largest area\nsites$area <- st_area(sites)\nsite_meta <- sites |>\n  dplyr::group_by(cluster) |>\n  dplyr::filter(area == max(area)) |>\n  as.data.frame() |>\n  dplyr::select(name, landuse, military, cluster) |>\n  dplyr::distinct()\n\npurrr::imap_dfr(\n  site_meta, ~data.frame(\n    label = .y, \n    sum_na = sum(is.na(.x)), \n    per_missing = round(100*sum(is.na(.x))/length(.x))\n  )\n)\n\n     label sum_na per_missing\n1     name   1220          53\n2  landuse   1366          59\n3 military    597          26\n4  cluster      0           0\n\nsites_clustered <- sites_clustered |>\n  dplyr::arrange(cluster) |>\n  dplyr::left_join(site_meta, by = \"cluster\") |>\n  dplyr::mutate(csize = comp$csize) |>\n  dplyr::select(cluster, csize, primary_name = name, primary_landuse = landuse, primary_military = military, geometry)\n\nsites_clustered$area <- st_area(sites_clustered)\n\n\nleaflet(sites_clustered) |>\n  addTiles() |>\n  setView(0,52, 8) |>\n  addPolygons(\n    label = ~primary_name, weight = 0, fillColor = \"red\",  \n    popup = ~paste(\n      cluster, csize, primary_name, \n      primary_landuse, primary_military, \n      round(area),\n      sep = \"<br>\"\n    )\n  )\n\n\n\n\n\n\n\ndb <- connect_postgres()\nst_write(sites_clustered, db, \"mil_bound_clust_osm\")\n\nNote: method with signature 'DBIObject#sf' chosen for function 'dbDataType',\n target signature 'PqConnection#sf'.\n \"PqConnection#ANY\" would also be valid\n\nDBI::dbDisconnect(db)"
  },
  {
    "objectID": "postgis-bbox-query.html",
    "href": "postgis-bbox-query.html",
    "title": "PostgreSQL GIS Query by Bounding Box",
    "section": "",
    "text": "Geospatial Extent\n\n\n\n\n\nGeospatial Extent\n\n\n\n\n\n\nWhich military sites are in the geospatial extent?\n\n# create bounding box\nbbox <- st_bbox(p202r24)\n\n# query database\ndb <- connect_postgres()\n\n# build query\nq <- query_bounding_box(bbox[1], bbox[2], bbox[3], bbox[4], tbl = \"mil_boundaries_osm\")\nq2 <- query_bounding_box(bbox[1], bbox[2], bbox[3], bbox[4])\nboundaries <- st_read(db, query = q)\nbuildings <- st_read(db, query = q2)\nDBI::dbDisconnect(db)\n\n# clip to extent\nboundaries <- boundaries[p202r24,]\nbuildings <- buildings[p202r24,]\n\n\nggplot() +\n  geom_sf(data = p202r24, fill = NA, colour = \"black\", inherit.aes = FALSE) + \n  geom_sf(data = boundaries, fill = \"red\", colour = NA, alpha = 0.2, inherit.aes = FALSE)\n\n\n\n\nBoundaries\n\n\n\n\n\nggplot() +\n  geom_sf(data = p202r24, fill = NA, colour = \"black\", inherit.aes = FALSE) + \n  geom_sf(data = buildings, fill = \"red\", colour = \"red\", alpha = 0.2, inherit.aes = FALSE)\n\n\n\n\nBuildings"
  },
  {
    "objectID": "selecting-data.html",
    "href": "selecting-data.html",
    "title": "Selecting Landsat Data",
    "section": "",
    "text": "library(rnaturalearth)\nlibrary(sf)\n\nLinking to GEOS 3.9.1, GDAL 3.4.3, PROJ 7.2.1; sf_use_s2() is TRUE\n\nlibrary(ggplot2)\n\nuk <- ne_countries(country= \"united kingdom\") |>\n  sf::st_as_sf()\n\nuk_grid <- st_make_grid(uk, what = \"centers\", n = 40) |>\n  st_as_sf()\n\nuk_grid$id <- 1:nrow(uk_grid)\n\nggplot() +\n  geom_sf(data = uk_grid) + \n  geom_sf(data = uk, fill = NA) \n\n\n\nuk_grid_clipped <- uk_grid[uk,]\n\nggplot() +\n  geom_sf(data = uk_grid_clipped)\n\n\n\nst_area(uk)/1e6\n\n248926.4 [m^2]\n\n# 243,610 km (google)\n\narea <- st_make_grid(uk,  n = 40) |>\n  st_as_sf() |>\n  st_area() / 1e6 |>\n  head()\n\nmean(area) |> as.numeric()\n\n[1] 361.6751\n\n\n\nmeta <- readr::read_csv(\"data/landsat_ot_c2_l2_631c33e385785a47/landsat_ot_c2_l2_631c33e385785a47.txt\")\n\nRows: 1883 Columns: 59\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (28): Landsat Product Identifier L2, Landsat Product Identifier L1, Lan...\ndbl  (26): Result Number, Collection Number, WRS Path, Target WRS Path, Roll...\ndttm  (2): Start Time, Stop Time\ndate  (3): Date Acquired, Date Product Generated L2, Date Product Generated L1\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeta |> dplyr::select(\n    PATH = `WRS Path`,\n    ROW = `WRS Row`,\n    `Date Acquired`,\n    `Land Cloud Cover`,\n    `Entity ID`\n  ) |>\n  dplyr::mutate(Month = paste0(substr(`Date Acquired`, 1, 8), \"01\")) |>\n  dplyr::mutate(ROW = as.numeric(ROW)) |> \n  dplyr::filter(PATH %in% c(201, 202), ROW == 24) |>\n  dplyr::filter(`Date Acquired` > \"2021-06-01\") |>\n  dplyr::group_by(Month) |>\n  dplyr::filter(`Land Cloud Cover` == min(`Land Cloud Cover`))\n\n# A tibble: 7 × 6\n# Groups:   Month [7]\n   PATH   ROW `Date Acquired` `Land Cloud Cover` `Entity ID`           Month    \n  <dbl> <dbl> <date>                       <dbl> <chr>                 <chr>    \n1   202    24 2022-01-14                    8.2  LC92020242022014LGN00 2022-01-…\n2   202    24 2022-03-19                    0.04 LC92020242022078LGN00 2022-03-…\n3   201    24 2022-04-21                    9.63 LC82010242022111LGN00 2022-04-…\n4   202    24 2022-05-14                   11.2  LC82020242022134LGN00 2022-05-…\n5   202    24 2022-06-15                    4.24 LC82020242022166LGN00 2022-06-…\n6   201    24 2022-07-18                    0.81 LC92010242022199LGN00 2022-07-…\n7   201    24 2022-08-11                    0.02 LC82010242022223LGN00 2022-08-…\n\n\n\nwrs2_d <- st_read(\"data/WRS2_descending_0/WRS2_descending.shp\")\n\nReading layer `WRS2_descending' from data source \n  `C:\\Users\\lukeh\\Documents\\quarto\\seven\\data\\WRS2_descending_0\\WRS2_descending.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 28892 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -82.6401 xmax: 180 ymax: 82.6401\nGeodetic CRS:  WGS 84\n\nwrs2_d <- st_transform(wrs2_d, st_crs(uk_grid_clipped))\nwrs2_d_clipped <- wrs2_d[uk,]\n\nmeta <- readr::read_csv(\"data/landsat_ot_c2_l2_631c33e385785a47/landsat_ot_c2_l2_631c33e385785a47.txt\")\n\nRows: 1883 Columns: 59\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (28): Landsat Product Identifier L2, Landsat Product Identifier L1, Lan...\ndbl  (26): Result Number, Collection Number, WRS Path, Target WRS Path, Roll...\ndttm  (2): Start Time, Stop Time\ndate  (3): Date Acquired, Date Product Generated L2, Date Product Generated L1\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmeta <- meta |>\n  dplyr::select(\n    PATH = `WRS Path`,\n    ROW = `WRS Row`,\n    `Date Acquired`,\n    `Land Cloud Cover`,\n    `Entity ID`\n  ) |>\n  dplyr::mutate(Month = paste0(substr(`Date Acquired`, 1, 8), \"01\")) |>\n  dplyr::group_by(\n    PATH, ROW, Month\n  ) |>\n  dplyr::filter(`Land Cloud Cover` == min(`Land Cloud Cover`)) |>\n  dplyr::mutate(ROW = as.numeric(ROW)) |>\n  dplyr::filter(`Date Acquired` >= \"2021-07-01\")\n\n\nd <- st_intersects(uk_grid_clipped, wrs2_d_clipped) |> \n  as.data.frame() \n  \npath_row <- wrs2_d_clipped[d$col.id,] |>\n  as.data.frame() |>\n  dplyr::select(PATH, ROW)\n\ndplyr::bind_cols(d, path_row) |>\n  dplyr::left_join(meta) |>\n  dplyr::group_by(row.id, Month) |>\n  dplyr::filter(`Land Cloud Cover` == min(`Land Cloud Cover`)) |>\n  dplyr::ungroup() |>\n  dplyr::select(PATH, ROW, `Date Acquired`, `Land Cloud Cover`, `Entity ID`, Month) |>\n  dplyr::distinct() |>\n  dplyr::filter(PATH %in% c(201, 202), ROW == 24) |>\n  dplyr::arrange(`Date Acquired`) |>\n  dplyr::group_by(Month) |>\n  dplyr::filter(`Land Cloud Cover` == min(`Land Cloud Cover`))\n\nJoining, by = c(\"PATH\", \"ROW\")\n\n\n# A tibble: 7 × 6\n# Groups:   Month [7]\n   PATH   ROW `Date Acquired` `Land Cloud Cover` `Entity ID`           Month    \n  <dbl> <dbl> <date>                       <dbl> <chr>                 <chr>    \n1   202    24 2022-01-14                    8.2  LC92020242022014LGN00 2022-01-…\n2   202    24 2022-03-19                    0.04 LC92020242022078LGN00 2022-03-…\n3   201    24 2022-04-21                    9.63 LC82010242022111LGN00 2022-04-…\n4   202    24 2022-05-14                   11.2  LC82020242022134LGN00 2022-05-…\n5   202    24 2022-06-15                    4.24 LC82020242022166LGN00 2022-06-…\n6   201    24 2022-07-18                    0.81 LC92010242022199LGN00 2022-07-…\n7   201    24 2022-08-11                    0.02 LC82010242022223LGN00 2022-08-…"
  },
  {
    "objectID": "site-lst-ratio.html",
    "href": "site-lst-ratio.html",
    "title": "Site LST Location Quotient",
    "section": "",
    "text": "db <- connect_postgres()\nDBI::dbListTables(db)\n\n[1] \"geography_columns\"     \"geometry_columns\"      \"spatial_ref_sys\"      \n[4] \"mil_boundaries_osm\"    \"mil_build_os\"          \"mil_build_features\"   \n[7] \"mil_bound_clust_osm\"   \"sites_202024_20220826\"\n\nsites <- st_read(db, \"mil_bound_clust_osm\")\nDBI::dbDisconnect(db)\n\n\nCalculate LST for Path and Row\n\nd <- \"../../../OneDrive/Data/landstat/LC09_L2SP_202024_20220826_20220830_02_T1/\"\nf <- list.files(d)\nb4_tif <- file.path(d, f[grepl(\"B4\", f)])\nb5_tif <- file.path(d, f[grepl(\"B5\", f)])\nb10_tif <- file.path(d, f[grepl(\"B10\", f)])\nmeta <- file.path(d, f[grepl(\"MTL.txt\", f)])\nLST <- calculate_lst(b4_tif, b5_tif, b10_tif, meta)\n\n\n\nRemove Cloud and Water\n\nqa <- raster(file.path(d, \"LC09_L2SP_202024_20220826_20220830_02_T1_QA_PIXEL.TIF\"))\nqa_lu <- readr::read_csv(\"data/qa_pixel.csv\")\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\nRows: 21 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (13): Fill, Dilated Cloud, Cirrus, Cloud, Cloud Shadow, Snow, Clear, Wat...\ndbl  (1): Pixel Value\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmask_values <- qa_lu |>\n  dplyr::filter(Cloud == \"Yes\" | Water == \"Yes\") |>\n  dplyr::pull(`Pixel Value`)\n\nqa[qa %in% mask_values] <- NA\nLSTm <- mask(LST, qa)\nLSTm[LSTm<0] <- NA\nplot(LSTm)\n\n\n\n\n\n\nCalculate LST by Site\n\nlstm2 <- projectRaster(LSTm, crs = crs(sites))\nsites_202024_20220826 <- st_crop(sites, lstm2)\n\nWarning: attribute variables are assumed to be spatially constant throughout all\ngeometries\n\n# This takes a while...\navg_lst <- raster::extract(lstm2, sites_202024_20220826, mean, na.rm = TRUE)\nsites_202024_20220826$lst <- as.numeric(avg_lst)\nmean_lst <- cellStats(lstm2, mean)\nsites_202024_20220826$lst_lq <- sites_202024_20220826$lst/mean_lst\nsummary(sites_202024_20220826)\n\n    cluster           csize         primary_name       primary_landuse   \n Min.   : 286.0   Min.   :  1.000   Length:844         Length:844        \n 1st Qu.: 698.8   1st Qu.:  1.000   Class :character   Class :character  \n Median : 941.5   Median :  1.000   Mode  :character   Mode  :character  \n Mean   :1085.0   Mean   :  1.962                                        \n 3rd Qu.:1281.5   3rd Qu.:  1.000                                        \n Max.   :2133.0   Max.   :124.000                                        \n                                                                         \n primary_military        area                    geometry        lst        \n Length:844         Min.   :        4   MULTIPOLYGON :  3   Min.   :0.0319  \n Class :character   1st Qu.:       29   POLYGON      :841   1st Qu.:0.9374  \n Mode  :character   Median :      720   epsg:4326    :  0   Median :1.6190  \n                    Mean   :   720672   +proj=long...:  0   Mean   :1.6789  \n                    3rd Qu.:    19774                       3rd Qu.:2.4025  \n                    Max.   :105853345                       Max.   :4.4420  \n                                                            NA's   :467     \n     lst_lq      \n Min.   :0.0188  \n 1st Qu.:0.5526  \n Median :0.9544  \n Mean   :0.9897  \n 3rd Qu.:1.4163  \n Max.   :2.6186  \n NA's   :467     \n\n\n\ndb <- connect_postgres()\nst_write(sites_202024_20220826, db,\"sites_202024_20220826\")\n\nNote: method with signature 'DBIObject#sf' chosen for function 'dbDataType',\n target signature 'PqConnection#sf'.\n \"PqConnection#ANY\" would also be valid\n\nDBI::dbDisconnect(db)\n\n\npal <- colorNumeric(c(\"#0C2C84\", \"#41B6C4\", \"#FFFFCC\"), sites_202024_20220826$lst_lq,\n  na.color = \"transparent\")\n\n\nleaflet(options = leafletOptions(minZoom = 8, maxZoom = 17)) |>\n  addTiles(group = \"OSM (default)\") |>\n  addProviderTiles(providers$Stamen.Toner, group = \"Toner\") |>\n  addProviderTiles(providers$Stamen.TonerLite, group = \"Toner Lite\") |>\n  setView(0,52, 8) |>\n  addPolygons(\n    data = sites_202024_20220826, fillColor =  ~pal(lst_lq), \n    color = \"black\", weight = 0, fillOpacity = 0.8,\n    label = ~primary_name, \n    popup = ~paste(\n      cluster, csize, primary_name, \n      primary_landuse, primary_military, \n      round(area),\n      round(lst),\n      round(lst_lq, 1),\n      sep = \"<br>\"\n    )\n  ) |>\n  addLegend(pal = pal, values = sites_202024_20220826$lst_lq,\n    title = \"Location Quotient (LST)\")   |>\n  addLayersControl(\n    baseGroups = c(\"OSM (default)\", \"Toner\", \"Toner Lite\"),\n    options = layersControlOptions(collapsed = FALSE)\n  )"
  }
]